{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb366089",
   "metadata": {},
   "source": [
    "## Exploring different Document Processing Models\n",
    " \n",
    " **Goal**: An Agentic approach to explore different Document Processing Models for OCR, Layout Analysis, and Table Extraction.\n",
    " \n",
    " **Output**: A simple langgraph agent that explores different ocr techniques/models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90aefbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\u001b[1m Aimessagechunk Message \u001b[0m============================\n",
      "\n",
      "[{'thinking': 'The user has greeted me with \"Hello, world!\" and the system message indicates that no document has been uploaded yet. However, the instruction mentions that the user wants to process a document using all available OCR techniques.\\n\\nSince no document path is provided (the system message states \"No Document Uploaded\"), I cannot perform OCR yet. I should:\\n1. Greet the user\\n2. Acknowledge their request\\n3. Inform them that no document has been uploaded yet\\n4. Ask them to upload a document so I can proceed with OCR processing\\n\\nI should be helpful and ready to assist once they upload a document.', 'type': 'thinking', 'index': 0, 'signature': 'EvUFCkYICxgCKkAS1pcQGKQ6tP6RGDLwaMG5ok/5daHCKJj7+63FHQsJZU754Owx5VnS9YwtaoTg6yKK9Jxhyhc2y3rhzWHhM5/1Egwq/HlqXVRrRbo9eI8aDBN2XqVgFMxM8yM0mSIwkaDOA6RlzzIObJfd1Z3KYy5D+x0e7nHLUWGK2Fzp+MDliNDZJDWIkNJYT3BrjKtkKtwEYHbMWm44AL0T/9Ns1/w968gWf19LGt2/nSW7D5UtdjV41HS2/9rpOSZViSDUsLMrKc7vRXjeaTvLoAHwfiRxH3SukEPjcucguq3yG3KSFNjdLmVtTEVsjYFWvhmlpnWLd8Rbm9M8O1nFlIxgt13kH4bkOmRDCxZsY68vEOmNqbfpBeai4mmPYFwSHie79fCJaEIwXTaS7JyWtzLfuOEJQ28OYkSrXdoK6bbGx0cfQQF6CnUPhy5EEosPmFd4jmL6vI0WRkfQ+YUlmhlwE+KhIrlfzjgNuuAqkmPiTYUSEySQ3HV3JrL5NmPfLgsweFBfh4jUjp7aSwPMzoV9yc/iIqRJM96XZMFKoXBU+0T8ATGamBdVALhBf6kFQdaAyuWRAIwde97tSXOf6N1VJ0mI4SHPbam9TCXWUyACcaNJ/QMhCbiYuZjD9J2lNItTKsaQhFWjn7piffGQNOvHux9jp3hviNVKjxfNCmE236tWAO76XrUdwVSbpQXD7tV7rFdFJri+Fm4U9i0P8BI3PeYai6BVfB5eCwEN7ofC9AA1bPoVtRP9jwbXuVN0bK0mTtNnEgKIhjZQeALZ26BXyyHfyjyOfFzkOhNuCdSOzuL3jW3/DLM2Ly6/VrNuGyYjrtPxxTTQC4U2N7UPCcysdP1h8iYtIUsBPcz9/syhmLLMjqrcCx4Si06iRfTzdBi9Z9I+9HZitnsRWBS+NrRWz3+cxNSUQMyLnYwWrXxc/WHdTgNGGpoRRyMQEUYVlDL/Vh7cV8sDkU84PMyFAlUt86l5y7toQyuiBl0ywhY9LxgB'}, {'text': \"Hello! ðŸ‘‹ Welcome!\\n\\nI'm ready to help you process documents using OCR (Optical Character Recognition) techniques. However, I notice that **no document has been uploaded yet**.\\n\\n## What I can do for you:\\n\\nOnce you upload a document, I will:\\n- âœ… Extract text using all available OCR techniques/models\\n- âœ… Compare results from different OCR methods\\n- âœ… Answer any questions about the document content\\n- âœ… Analyze and extract relevant information\\n\\n## To get started:\\n\\nðŸ“¤ **Please upload the document** you'd like me to process (supported formats typically include: PDF, images like JPG, PNG, etc.)\\n\\nOnce you upload the document, I'll automatically:\\n1. Apply all available OCR techniques\\n2. Extract the text content\\n3. Provide you with the results\\n4. Answer any questions you have about the document\\n\\nGo ahead and upload your document whenever you're ready! ðŸš€\", 'type': 'text', 'index': 1}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=[{'thinking': 'The user has greeted me with \"Hello, world!\" and the system message indicates that no document has been uploaded yet. However, the instruction mentions that the user wants to process a document using all available OCR techniques.\\n\\nSince no document path is provided (the system message states \"No Document Uploaded\"), I cannot perform OCR yet. I should:\\n1. Greet the user\\n2. Acknowledge their request\\n3. Inform them that no document has been uploaded yet\\n4. Ask them to upload a document so I can proceed with OCR processing\\n\\nI should be helpful and ready to assist once they upload a document.', 'type': 'thinking', 'index': 0, 'signature': 'EvUFCkYICxgCKkAS1pcQGKQ6tP6RGDLwaMG5ok/5daHCKJj7+63FHQsJZU754Owx5VnS9YwtaoTg6yKK9Jxhyhc2y3rhzWHhM5/1Egwq/HlqXVRrRbo9eI8aDBN2XqVgFMxM8yM0mSIwkaDOA6RlzzIObJfd1Z3KYy5D+x0e7nHLUWGK2Fzp+MDliNDZJDWIkNJYT3BrjKtkKtwEYHbMWm44AL0T/9Ns1/w968gWf19LGt2/nSW7D5UtdjV41HS2/9rpOSZViSDUsLMrKc7vRXjeaTvLoAHwfiRxH3SukEPjcucguq3yG3KSFNjdLmVtTEVsjYFWvhmlpnWLd8Rbm9M8O1nFlIxgt13kH4bkOmRDCxZsY68vEOmNqbfpBeai4mmPYFwSHie79fCJaEIwXTaS7JyWtzLfuOEJQ28OYkSrXdoK6bbGx0cfQQF6CnUPhy5EEosPmFd4jmL6vI0WRkfQ+YUlmhlwE+KhIrlfzjgNuuAqkmPiTYUSEySQ3HV3JrL5NmPfLgsweFBfh4jUjp7aSwPMzoV9yc/iIqRJM96XZMFKoXBU+0T8ATGamBdVALhBf6kFQdaAyuWRAIwde97tSXOf6N1VJ0mI4SHPbam9TCXWUyACcaNJ/QMhCbiYuZjD9J2lNItTKsaQhFWjn7piffGQNOvHux9jp3hviNVKjxfNCmE236tWAO76XrUdwVSbpQXD7tV7rFdFJri+Fm4U9i0P8BI3PeYai6BVfB5eCwEN7ofC9AA1bPoVtRP9jwbXuVN0bK0mTtNnEgKIhjZQeALZ26BXyyHfyjyOfFzkOhNuCdSOzuL3jW3/DLM2Ly6/VrNuGyYjrtPxxTTQC4U2N7UPCcysdP1h8iYtIUsBPcz9/syhmLLMjqrcCx4Si06iRfTzdBi9Z9I+9HZitnsRWBS+NrRWz3+cxNSUQMyLnYwWrXxc/WHdTgNGGpoRRyMQEUYVlDL/Vh7cV8sDkU84PMyFAlUt86l5y7toQyuiBl0ywhY9LxgB'}, {'text': \"Hello! ðŸ‘‹ Welcome!\\n\\nI'm ready to help you process documents using OCR (Optical Character Recognition) techniques. However, I notice that **no document has been uploaded yet**.\\n\\n## What I can do for you:\\n\\nOnce you upload a document, I will:\\n- âœ… Extract text using all available OCR techniques/models\\n- âœ… Compare results from different OCR methods\\n- âœ… Answer any questions about the document content\\n- âœ… Analyze and extract relevant information\\n\\n## To get started:\\n\\nðŸ“¤ **Please upload the document** you'd like me to process (supported formats typically include: PDF, images like JPG, PNG, etc.)\\n\\nOnce you upload the document, I'll automatically:\\n1. Apply all available OCR techniques\\n2. Extract the text content\\n3. Provide you with the results\\n4. Answer any questions you have about the document\\n\\nGo ahead and upload your document whenever you're ready! ðŸš€\", 'type': 'text', 'index': 1}], additional_kwargs={}, response_metadata={'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='lc_run--019bbde5-37bb-7022-9396-4337e1b737e1', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 196, 'output_tokens': 360, 'total_tokens': 556, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, tool_call_chunks=[], chunk_position='last')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up a react agent with LangChain\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import AIMessageChunk, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langsmith import traceable\n",
    "from prompts import DOCUMENT_AGENT_SYSTEM_PROMPT, USER_MESSAGE_TEMPLATE\n",
    "\n",
    "load_dotenv()\n",
    "# conn = connect(\"langgraph_checkpoints.db\")\n",
    "# checkpointer = SqliteSaver(conn=conn)\n",
    "checkpointer = InMemorySaver()\n",
    "llm = init_chat_model(\n",
    "    \"anthropic:claude-sonnet-4-5-20250929\", temperature=1, thinking={\"type\": \"enabled\", \"budget_tokens\": 10000}\n",
    ")\n",
    "\n",
    "document_agent = create_agent(\n",
    "    model=llm,\n",
    "    system_prompt=DOCUMENT_AGENT_SYSTEM_PROMPT,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "config = RunnableConfig(configurable={\"thread_id\": \"test_thread\"})\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(USER_MESSAGE_TEMPLATE.format(message=\"Hello, world!\", document_path=\"No Document Uploaded\"))\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "@traceable(name=\"DocumentAgentInteraction\")\n",
    "def agent_execution():\n",
    "    \"\"\"Execute the document agent and streams the response.\"\"\"\n",
    "    ai_message = AIMessageChunk(content=[])\n",
    "\n",
    "    for _, chunk in document_agent.stream(inputs, stream_mode=[\"messages\"], config=config):\n",
    "        ai_message += chunk[0]\n",
    "\n",
    "    ai_message.pretty_print()\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "agent_execution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
