# Work Item 1.3: Digital vs Scanned PDF Handling

## Overview

**What:** Compare processing strategies for digital (text-based) PDFs vs scanned (image-based) PDFs and create a decision tree for routing documents.

**Why:** Digital PDFs can be processed much faster by extracting embedded text, while scanned PDFs require OCR. Understanding when to use each approach (or both) is critical for building efficient pipelines that don't waste resources running OCR on digital documents.

**Deliverable:** 
- Notebook comparing digital vs scanned PDF processing
- Decision tree for document routing
- Hybrid approach implementation (try text extraction first, fallback to OCR)
- Performance benchmarks

**Estimated Time:** 2 hours

**Prerequisites:** 
- Work Item 1.1 complete (OCR engines understood)
- Work Item 1.2 complete (Docling pipeline understood)

---

## Learning Objectives

By the end of this work item, you will understand:
- How to detect if a PDF is digital or scanned
- Text extraction methods for digital PDFs (PyMuPDF, pdfplumber, etc.)
- When OCR is necessary vs wasteful
- How to build a hybrid approach that optimizes for both
- Quality validation to catch edge cases (digital PDFs with poor text layer)

---

## Sub-Tasks

### Task 1.3.1: Digital PDF Text Extraction
**Time:** 30 minutes  
**Priority:** High

**Goal:** Explore text extraction from digital PDFs using PyMuPDF.

**Implementation Steps:**
1. Create `experiments/pdf_handling.ipynb`
2. Load sample digital PDFs
3. Extract text using PyMuPDF (fitz)
4. Measure extraction speed
5. Analyze text quality and formatting preservation

**Success Criteria:**
- [ ] Successfully extract text from digital PDFs
- [ ] Measure extraction speed (should be <1 second per page)
- [ ] Document text quality and formatting issues
- [ ] Compare text extraction vs OCR on same document

**Learning Outcome:** Understand fast path for digital documents.

---

### Task 1.3.2: PDF Type Detection
**Time:** 30 minutes  
**Priority:** High

**Goal:** Build a function to detect if a PDF is digital or scanned.

**Implementation Steps:**
1. Create `app/pdf/detector.py`
2. Implement detection logic:
   - Extract text from first few pages
   - Calculate text/image ratio
   - Check for embedded fonts
   - Heuristics for "mostly text" vs "mostly images"
3. Test on sample PDFs (digital, scanned, hybrid)

**Files to Create:**
- `app/pdf/__init__.py`
- `app/pdf/detector.py`

**Success Criteria:**
- [ ] `detect_pdf_type()` function accurately classifies PDFs
- [ ] Handles edge cases (hybrid PDFs with text + images)
- [ ] Fast detection (doesn't process entire document)
- [ ] Returns confidence score or detailed metadata

**Code Reference:**
```python
from enum import Enum

class PDFType(str, Enum):
    DIGITAL = "digital"
    SCANNED = "scanned"
    HYBRID = "hybrid"

class PDFTypeDetector:
    def detect(self, pdf_path: Path) -> PDFType:
        """Detect if PDF is digital, scanned, or hybrid."""
        pass
```

**Learning Outcome:** Learn to classify documents before processing.

---

### Task 1.3.3: Hybrid Processing Strategy
**Time:** 45 minutes  
**Priority:** High

**Goal:** Implement a hybrid processor that tries text extraction first, falls back to OCR if needed.

**Implementation Steps:**
1. Create `app/pdf/processor.py`
2. Implement `PDFProcessor` class:
   - Detect PDF type
   - For digital: extract text directly
   - For scanned: run OCR pipeline
   - For hybrid: extract text, run OCR on image regions
3. Add quality validation:
   - Check if extracted text is meaningful
   - Detect poor text layers (garbled text)
   - Fallback to OCR if text quality is low

**Files to Create:**
- `app/pdf/processor.py`

**Success Criteria:**
- [ ] Correctly routes digital PDFs to text extraction
- [ ] Correctly routes scanned PDFs to OCR
- [ ] Handles hybrid PDFs appropriately
- [ ] Quality validation catches poor text layers
- [ ] Fast processing for digital PDFs

**Learning Outcome:** Build intelligent document routing.

---

### Task 1.3.4: Performance Benchmarking
**Time:** 30 minutes  
**Priority:** Medium

**Goal:** Compare processing speed and quality across strategies.

**Implementation Steps:**
1. Collect test PDFs:
   - 5 digital PDFs
   - 5 scanned PDFs
   - 5 hybrid PDFs
2. Benchmark each approach:
   - Direct text extraction time
   - OCR processing time
   - Hybrid approach time
3. Create comparison table in notebook

**Success Criteria:**
- [ ] Timing data for all approaches
- [ ] Quality comparison (when applicable)
- [ ] Clear performance advantages documented
- [ ] Resource usage noted (CPU, memory)

**Learning Outcome:** Quantify the value of intelligent routing.

---

### Task 1.3.5: Decision Tree Documentation
**Time:** 30 minutes  
**Priority:** Medium

**Goal:** Create visual decision tree for PDF processing strategy.

**Implementation Steps:**
1. Create `docs/pdf-processing-decision-tree.md`
2. Document decision logic:
   - When to use text extraction
   - When to use OCR
   - When to use hybrid
   - Edge cases and fallbacks
3. Include flowchart/diagram
4. Add code examples

**Files to Create:**
- `docs/pdf-processing-decision-tree.md`

**Success Criteria:**
- [ ] Clear decision tree created
- [ ] All edge cases covered
- [ ] Visual diagram included
- [ ] Code examples provided

**Learning Outcome:** Communicate processing strategy clearly.

---

## Files to Create

- `experiments/pdf_handling.ipynb` - PDF processing comparison
- `app/pdf/__init__.py`
- `app/pdf/detector.py` - PDF type detection
- `app/pdf/processor.py` - Hybrid processor
- `docs/pdf-processing-decision-tree.md` - Decision guide

---

## Decision Tree (Preview)

```
PDF Document
    │
    ├─→ Detect PDF Type
    │      │
    │      ├─→ Digital (text-based)
    │      │      │
    │      │      └─→ Extract text with PyMuPDF
    │      │             │
    │      │             ├─→ Quality check passes → Done (fast!)
    │      │             └─→ Quality check fails → Fallback to OCR
    │      │
    │      ├─→ Scanned (image-based)
    │      │      │
    │      │      └─→ Run OCR pipeline (Docling or chosen engine)
    │      │
    │      └─→ Hybrid (mixed)
    │             │
    │             ├─→ Extract text where available
    │             └─→ Run OCR on image regions
    │
    └─→ Output: Structured text + metadata
```

---

## Notes & Tips

**Text Quality Checks:**
- Check character count (too few = likely scanned)
- Look for gibberish/encoding issues
- Verify presence of meaningful words
- Check text extraction coverage (% of page)

**Common Pitfalls:**
- Some "digital" PDFs have poor OCR layers → need validation
- Hybrid PDFs require careful handling of overlapping content
- Page orientation can affect text extraction

**Performance Tips:**
- Only check first 1-3 pages for type detection
- Cache detection results
- Process pages in parallel when possible

---

## Acceptance Criteria

This work item is complete when:
- ✅ Can accurately detect PDF type (digital vs scanned)
- ✅ Hybrid processor implemented and tested
- ✅ Performance benchmarks completed
- ✅ Decision tree documented
- ✅ Understand when to use each approach

---

## Related Work Items

- **Previous:** [Work Item 1.2: Docling Pipeline Deep Dive](./1.2-docling-deep-dive.md)
- **Next:** Work Item 2.1: Chunking Strategy Experiments (Module 2)
- **Enables:** Efficient document processing pipeline for RAG
